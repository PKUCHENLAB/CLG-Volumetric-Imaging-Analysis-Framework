{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLG Step 2: Single Neuron Signal Extraction & 3D Calibration\n",
    "\n",
    "This notebook implements the core **\"CLG\" (Comprehensive Label-Guided)** step described in the paper.\n",
    "\n",
    "**Key Functions:**\n",
    "1.  **Load Data**: Reads registered functional calcium imaging data (TIFF) and the corresponding 3D structural segmentation masks (from Cellpose).\n",
    "2.  **Map Slices**: Aligns functional imaging planes to the high-resolution structural 3D volume using a provided mapping file.\n",
    "3.  **Extract Traces**: Extracts mean fluorescence traces for each ROI on every functional plane.\n",
    "4.  **3D Calibration (Merge)**: Identifies ROIs belonging to the same 3D neuron (spanning multiple z-planes) based on unique Cellpose IDs and merges their signals to eliminate **axial overcounting**.\n",
    "5.  **Save Results**: Exports the calibrated single-neuron activity matrix (`trace`), centroids (`pos`), and metadata for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Experiment: spon\n",
      "Data Directory: Z:\\GDZ\\zebrafish_ptz\\20220317fish4\\spon\\result_denoised_registed\n",
      "Mask File: Z:\\GDZ\\zebrafish_ptz\\20220317fish4\\label\\C1-fish4 3d double_tiff_reconstructed_imNor_30_0.001000_jupyter_cp2masks.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from skimage.measure import regionprops\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio  # For saving .mat files compatible with legacy code if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up paths - PLEASE UPDATE THESE FOR YOUR DATA\n",
    "BASE_DIR = r'main/extraction/fish4_example'\n",
    "EXPERIMENT = 'spon'  # Subfolder name\n",
    "\n",
    "# Input directories\n",
    "FUNC_DATA_DIR = os.path.join(BASE_DIR, EXPERIMENT, 'result_denoised_registed')\n",
    "MAPPING_FILE = os.path.join(BASE_DIR, EXPERIMENT, 'spon.txt')  # Slice mapping file\n",
    "MASK_DIR = os.path.join(BASE_DIR, 'label')\n",
    "MASK_FILENAME = 'C1-fish4 3d double_tiff_reconstructed_imNor_30_0.001000_jupyter_cp2masks.tif'\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, EXPERIMENT, 'extraction_results')\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "print(f\"Processing Experiment: {EXPERIMENT}\")\n",
    "print(f\"Data Directory: {FUNC_DATA_DIR}\")\n",
    "print(f\"Mask File: {os.path.join(MASK_DIR, MASK_FILENAME)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Structural 3D Masks\n",
    "Load the 3D segmentation result from Cellpose. Each unique integer ID in this volume represents a distinct 3D neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3D Mask Volume...\n",
      "Mask Volume Shape: (301, 1024, 1024)\n",
      "Calculating 3D centroids...\n",
      "Found 67414 unique 3D neurons.\n"
     ]
    }
   ],
   "source": [
    "mask_path = os.path.join(MASK_DIR, MASK_FILENAME)\n",
    "print(\"Loading 3D Mask Volume...\")\n",
    "mask_3d = tifffile.imread(mask_path)\n",
    "print(f\"Mask Volume Shape: {mask_3d.shape}\")\n",
    "\n",
    "# Calculate 3D Centroids for all neurons (useful for visualization later)\n",
    "print(\"Calculating 3D centroids...\")\n",
    "props = regionprops(mask_3d)\n",
    "centroids_3d = {prop.label: prop.centroid for prop in props}\n",
    "print(f\"Found {len(centroids_3d)} unique 3D neurons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Slice Mapping\n",
    "Read the text file that maps each Functional Z-plane (low res) to a specific Structural Z-plane (high res)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping loaded successfully.\n",
      "   FuncSlice  StructSlice\n",
      "0          2           85\n",
      "1          3           92\n",
      "2          4           99\n",
      "3          5          106\n",
      "4          6          111\n"
     ]
    }
   ],
   "source": [
    "# Read mapping file (Format: FuncSlice-StructSlice, e.g., 1-48)\n",
    "# Note: Adjust the separator ('-') or columns as per your specific file format\n",
    "try:\n",
    "    mapping_df = pd.read_csv(MAPPING_FILE, sep='-', header=None, names=['FuncSlice', 'StructSlice'])\n",
    "    print(\"Mapping loaded successfully.\")\n",
    "    print(mapping_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading mapping file: {e}\")\n",
    "\n",
    "# Create a dictionary for easy lookup: func_z -> struct_z\n",
    "slice_map = dict(zip(mapping_df['FuncSlice'], mapping_df['StructSlice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Raw Signals (Per Plane)\n",
    "Iterate through each functional plane, find its corresponding mask slice, and extract activity traces.\n",
    "Note: This step generates \"redundant\" traces (same neuron may be extracted multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store raw extraction results\n",
    "raw_traces = []\n",
    "raw_nuc_indices = []\n",
    "raw_positions = []\n",
    "raw_areas = []\n",
    "slice_info = []\n",
    "\n",
    "# Determine range of slices (assuming file naming z_02.tif, etc.)\n",
    "func_slices = sorted(slice_map.keys())\n",
    "\n",
    "print(\"Starting Signal Extraction...\")\n",
    "total_neurons = 0\n",
    "for func_z in tqdm(func_slices):\n",
    "    # 1. Load Functional Image\n",
    "    # Filename format: z_02.tif. Adjust pattern if needed.\n",
    "    func_img_path = os.path.join(FUNC_DATA_DIR, f'z_{func_z:02d}.tif')\n",
    "    if not os.path.exists(func_img_path):\n",
    "        print(f\"Warning: File not found {func_img_path}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # 2. Get Corresponding Mask Slice\n",
    "    struct_z = slice_map[func_z]\n",
    "    mask_z_idx = struct_z - 1 \n",
    "    if mask_z_idx >= mask_3d.shape[0]:\n",
    "        print(f\"Warning: Mask slice {mask_z_idx} out of bounds. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Print which slices we are processing\n",
    "    print(f\"Reading functional image slice {func_z}, corresponding to structural template slice {struct_z} (Python index: {mask_z_idx}).\")\n",
    "\n",
    "    func_img = tifffile.imread(func_img_path)\n",
    "    \n",
    "    # tif图像读取默认就是(T, H, W)的格式   \n",
    "    num_frames, h, w = func_img.shape\n",
    "\n",
    "    mask_slice = mask_3d[mask_z_idx, :, :]\n",
    "    \n",
    "    # 3. Iterate over each cell in this mask slice\n",
    "    unique_cells = np.unique(mask_slice)\n",
    "    unique_cells = unique_cells[unique_cells != 0] # Exclude background\n",
    "\n",
    "    # Flatten image for faster indexing: (Time, Pixels)\n",
    "    func_img_flat = func_img.reshape(num_frames, -1)\n",
    "\n",
    "    cell_count_this_slice = 0\n",
    "    for cell_id in unique_cells:\n",
    "        # Find pixels belonging to this cell\n",
    "        pixel_indices = np.where(mask_slice.ravel() == cell_id)[0]\n",
    "        \n",
    "        # Extract mean trace\n",
    "        cell_pixels = func_img_flat[:, pixel_indices]\n",
    "        mean_trace = np.mean(cell_pixels, axis=1)\n",
    "        \n",
    "        # Calculate 2D centroid on this slice for reference\n",
    "        ys, xs = np.unravel_index(pixel_indices, (h, w))\n",
    "        cy, cx = np.mean(ys), np.mean(xs)\n",
    "        \n",
    "        # Store Data\n",
    "        raw_traces.append(mean_trace)\n",
    "        raw_nuc_indices.append(cell_id)\n",
    "        raw_positions.append([mask_z_idx, cy, cx]) # Z, Y, X\n",
    "        raw_areas.append(len(pixel_indices))\n",
    "        slice_info.append(func_z)\n",
    "        cell_count_this_slice += 1\n",
    "    \n",
    "    total_neurons += cell_count_this_slice\n",
    "    print(f\"Extracted {cell_count_this_slice} cells in this slice, total extracted so far: {total_neurons}.\")\n",
    "\n",
    "print(f\"Extraction complete. Found {len(raw_traces)} raw ROIs across all planes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D Calibration (The CLG Step)\n",
    "Merge traces that belong to the same 3D neuron ID. This eliminates axial overcounting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for processing\n",
    "raw_traces_arr = np.array(raw_traces)\n",
    "raw_nuc_indices_arr = np.array(raw_nuc_indices)\n",
    "raw_areas_arr = np.array(raw_areas)\n",
    "raw_positions_arr = np.array(raw_positions)\n",
    "\n",
    "# Filter out small ROIs (Area <= 4 pixels) - Denoising step\n",
    "min_area = 4\n",
    "valid_mask = raw_areas_arr > min_area\n",
    "\n",
    "traces_filtered = raw_traces_arr[valid_mask]\n",
    "indices_filtered = raw_nuc_indices_arr[valid_mask]\n",
    "\n",
    "print(f\"After filtering small areas (<=4px): {len(indices_filtered)} ROIs remain.\")\n",
    "\n",
    "# --- MERGE DUPLICATES ---\n",
    "unique_ids = np.unique(indices_filtered)\n",
    "print(f\"Merging traces... Found {len(unique_ids)} unique 3D neurons.\")\n",
    "\n",
    "merged_traces = []\n",
    "merged_positions = []\n",
    "merged_ids = []\n",
    "\n",
    "for uid in tqdm(unique_ids):\n",
    "    # Find all instances of this neuron across slices\n",
    "    idx_matches = np.where(indices_filtered == uid)[0]\n",
    "    \n",
    "    if len(idx_matches) == 1:\n",
    "        # No overlap, just take the single trace\n",
    "        final_trace = traces_filtered[idx_matches[0]]\n",
    "    else:\n",
    "        # Overlap exists: Average the traces\n",
    "        # (weighted averaging could also be implemented here using areas)\n",
    "        final_trace = np.mean(traces_filtered[idx_matches], axis=0)\n",
    "    \n",
    "    # Get 3D Centroid from the original structural mask volume\n",
    "    if uid in centroids_3d:\n",
    "        # centroids_3d is (Z, Y, X)\n",
    "        pos_3d = centroids_3d[uid]\n",
    "    else:\n",
    "        pos_3d = [np.nan, np.nan, np.nan]\n",
    "        \n",
    "    merged_traces.append(final_trace)\n",
    "    merged_positions.append(pos_3d)\n",
    "    merged_ids.append(uid)\n",
    "\n",
    "merged_traces = np.array(merged_traces)\n",
    "merged_positions = np.array(merged_positions)\n",
    "merged_ids = np.array(merged_ids)\n",
    "\n",
    "print(f\"Final Calibrated Dataset: {merged_traces.shape[0]} Neurons, {merged_traces.shape[1]} Timepoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results\n",
    "Save the processed data for Step 3 (Network Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅用mat文件存储校准前后的结果，方便后续MATLAB处理及对比。\n",
    "\n",
    "# 保存calibration前（未merge前）的原始trace、pos和nucIndex数据\n",
    "sio.savemat(os.path.join(OUTPUT_DIR, 'CellTrace_before_calibration.mat'), \n",
    "            {\n",
    "                'trace': raw_traces,                # (N_raw_rois, T)\n",
    "                'pos': raw_positions,                    # (N_raw_rois, 3)\n",
    "                'nucIndex': raw_nuc_indices           # (N_raw_rois,)\n",
    "            })\n",
    "\n",
    "# 保存calibration后（merge后）的数据\n",
    "sio.savemat(os.path.join(OUTPUT_DIR, 'CellTrace_after_calibration.mat'), \n",
    "            {\n",
    "                'trace': merged_traces,            # (N_merged_neurons, T)\n",
    "                'pos': merged_positions,           # (N_merged_neurons, 3)\n",
    "                'nucIndex': merged_ids             # (N_merged_neurons,)\n",
    "            })\n",
    "\n",
    "print(f\"Data (before & after calibration) saved to {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

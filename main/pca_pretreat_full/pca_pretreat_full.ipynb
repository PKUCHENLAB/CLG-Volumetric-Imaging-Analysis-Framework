{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8e166b-21be-4f7a-9262-2e74bc913455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat,savemat\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "#from scipy.spatial.distance import squareform\n",
    "#from cupyx.scipy.spatial.distance import pdist\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import dff\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def remove_zero_rows_cols(matrix):\n",
    "   \n",
    "    matrix = matrix[~np.all(matrix == 0, axis=1)]\n",
    "    \n",
    "    matrix = matrix[:, ~np.all(matrix == 0, axis=0)]\n",
    "    return matrix\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties()\n",
    "\n",
    "font.set_size(5)  \n",
    "\n",
    "def compute_dff_Allen(traces, fs):\n",
    "   \n",
    "    index_long = int(300*fs//2*2+1)\n",
    "    index_short = int((10/3)*fs//2*2+1)\n",
    "\n",
    "    traces_dff = dff.compute_dff_windowed_median(traces,\n",
    "                                                 median_kernel_long=index_long,\n",
    "                                                 median_kernel_short=index_short)\n",
    "    \n",
    "    return traces_dff\n",
    "\n",
    "\n",
    "def compute_dff_Allen_parallel(traces, fs, n_jobs, batch_size):\n",
    "   \n",
    "    ROI_num = traces.shape[0]\n",
    "\n",
    "    traces_dff = Parallel(n_jobs=n_jobs)(delayed(compute_dff_Allen)(traces[i:min(i+batch_size, ROI_num), :], fs) for i in range(0, ROI_num, batch_size))\n",
    "\n",
    "    traces_dff = np.concatenate(traces_dff, axis=0)\n",
    "\n",
    "    return traces_dff\n",
    "\n",
    "def pca_reconstruction(data, variance_threshold=0.95, standardize=False):\n",
    "   \n",
    "    \n",
    "    \n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        data_processed = scaler.fit_transform(data)\n",
    "    else:\n",
    "        scaler = None\n",
    "        data_processed = data.copy()\n",
    "\n",
    "   \n",
    "    pca = PCA(n_components=variance_threshold, svd_solver='full')\n",
    "    pca.fit(data_processed)\n",
    "    \n",
    "    print(f\"Preserve variance proportion: {variance_threshold*100}%\")\n",
    "    print(f\"Select the number of principal components: {pca.n_components_}\")\n",
    "    print(f\"Cumulative explained variance: {np.sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "   \n",
    "    reconstructed_processed = pca.inverse_transform(pca.transform(data_processed))\n",
    "    \n",
    "   \n",
    "    if standardize:\n",
    "        reconstructed = scaler.inverse_transform(reconstructed_processed)\n",
    "    else:\n",
    "        reconstructed = reconstructed_processed\n",
    "\n",
    "    return reconstructed, pca, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46df6f-4366-4791-9c27-f4b3843a6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp='yourlocation/pca_pretreat_full/testData'\n",
    "datapath = '/'+exp;\n",
    "data = loadmat(os.path.join(datapath, \"Ori3dCellTrace.mat\"))\n",
    "\n",
    "nucArea = data['nucArea'] \n",
    "trace = data['trace'] \n",
    "nucIndex = data['nucIndex']\n",
    "\n",
    "smallArea = np.squeeze(nucArea <= 4) \n",
    "trace = np.delete(trace, np.where(smallArea), axis=0) \n",
    "\n",
    "nucIndex = np.delete(nucIndex, np.where(smallArea))\n",
    "\n",
    "del(data)\n",
    "\n",
    "traces_dff = compute_dff_Allen_parallel(trace, fs=1, n_jobs=30, batch_size=6)\n",
    "\n",
    "reconstructed, _ , _ = pca_reconstruction(traces_dff)#\n",
    "\n",
    "print('running corr1...')\n",
    "corr1 = squareform(pdist(reconstructed, \"correlation\"))\n",
    "\n",
    "corr1=1-corr1;\n",
    "indices = np.diag_indices(corr1.shape[0])\n",
    "corr1[indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb6b9a-87dc-49cf-9c36-0ac351050057",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucNo = np.unique(nucIndex) \n",
    "neural = np.zeros((len(nucNo), trace.shape[1]))\n",
    "for i in range(len(nucNo)): \n",
    "    sameNuc = nucIndex == nucNo[i] \n",
    "    if np.sum(sameNuc) > 1: \n",
    "     \n",
    "        neural[i, :] = np.mean(traces_dff[sameNuc, :], axis=0)\n",
    "    else: \n",
    "     \n",
    "        neural[i, :] = traces_dff[sameNuc, :]\n",
    "\n",
    "reconstructed, _ , _ = pca_reconstruction(neural)\n",
    "print('running corr2...')\n",
    "corr2 = squareform(pdist(reconstructed, \"correlation\"))\n",
    "\n",
    "corr2=1-corr2;\n",
    "indices = np.diag_indices(corr2.shape[0])\n",
    "corr2[indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cde90-82fe-4e51-9626-4060ea09af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle = np.triu(corr1, k=1)\n",
    "\n",
    "weights = upper_triangle[upper_triangle != 0]\n",
    "\n",
    "if np.isnan(weights).any():\n",
    "    weights = weights[~np.isnan(weights)]\n",
    "\n",
    "plt.hist(weights, bins=10000,\n",
    "         log=True,\n",
    "         density=True,\n",
    "         label='Gfunc',alpha=0.5)\n",
    "\n",
    "upper_triangle = np.triu(corr2, k=1)\n",
    "weights = upper_triangle[upper_triangle != 0]\n",
    "\n",
    "if np.isnan(weights).any():\n",
    "    weights = weights[~np.isnan(weights)]\n",
    "\n",
    "\n",
    "plt.hist(weights, bins=10000,\n",
    "         log=True,\n",
    "         density=True,\n",
    "         label='G3d',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Weights in Upper Triangle')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "del(upper_triangle,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6424667-9a4c-4da2-9648-c7581f144225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "ecGfun={}\n",
    "ecG3d={}\n",
    "\n",
    "eigenvalues, eigenvectors = eigsh(np.abs(corr1.astype('float32')), k=1, which='LM',)\n",
    "\n",
    "eigenvector_centrality = np.abs(eigenvectors[:, 0])\n",
    "eigenvector_centrality /= np.linalg.norm(eigenvector_centrality, ord=1) \n",
    "\n",
    "ecGfun[exp]=eigenvector_centrality * (corr1.shape[0] / corr2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149ae797-9598-466f-8df7-d6541cc65bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = eigsh(np.abs(corr2.astype('float32')), k=1, which='LM',)\n",
    "eigenvector_centrality = np.abs(eigenvectors[:, 0])\n",
    "eigenvector_centrality /= np.linalg.norm(eigenvector_centrality, ord=1)\n",
    "ecG3d[exp]=eigenvector_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb9846-9481-4085-b759-431e8422b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    (31, 119, 180),  \n",
    "    (174, 199, 232),\n",
    "    (255, 127, 14),  \n",
    "    (255, 187, 120), \n",
    "]\n",
    "\n",
    "colors = [(r/255, g/255, b/255) for r, g, b in colors]\n",
    "\n",
    "alphas = [0.5, 0.5, 0.5, 0.5] \n",
    "labels=['3d ptz', 'f ptz', '3d spon', 'f spon']\n",
    "\n",
    "\n",
    "for i, array in enumerate([ecG3d[exp], ecGfun[exp]]):\n",
    "    plt.hist(array, bins=1000, color=colors[i], alpha=alphas[i], \n",
    "             density=True,\n",
    "             label=labels[i]\n",
    "            )\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1babde40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_network(adj_matrix, indexs, threshold=0.95):\n",
    "    G = nx.Graph()\n",
    "    n = adj_matrix.shape[0]\n",
    "    \n",
    "\n",
    "    for i in range(n):\n",
    "        G.add_node(i, ind=indexs[i])\n",
    "    \n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if abs(adj_matrix[i, j]) > threshold:\n",
    "                G.add_edge(i, j)\n",
    "    \n",
    "\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc)\n",
    "\n",
    "\n",
    "def calculate_metrics(graph):\n",
    "    print('\\nDegree:')\n",
    "    degree = dict(graph.degree())\n",
    "    clustering = nx.clustering(graph)\n",
    "    metrics = {\n",
    "        'degree': degree,\n",
    "        'clustering': clustering\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_metric_hist(metric_name, metrics1, metrics2, G1, G2):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    cmName1='muted'\n",
    "    cmName2='pastel'\n",
    "\n",
    "    nodes = list(G1.nodes())\n",
    "    metrics1=[metrics1[metric_name][n] for n in nodes]\n",
    "\n",
    "    nodes = list(G2.nodes())\n",
    "    metrics2=[metrics2[metric_name][n] for n in nodes]\n",
    "    \n",
    "    labels=[f'{exp} treated \\nwithout 3d identified', f'{exp} treated \\nwith 3d identified']\n",
    "\n",
    "    bins=np.logspace(0,14,15,base=2)-0.5\n",
    "\n",
    "    \n",
    "\n",
    "    hist, bins = np.histogram(metrics1, \n",
    "                              bins=bins, \n",
    "                              density=True);\n",
    "    x=(bins[:-1]+bins[1:])/2\n",
    "    \n",
    "    plt.plot(x[hist>0],hist[hist>0],'o-',\n",
    "             markersize='12',\n",
    "             color=sns.color_palette(cmName2)[0],\n",
    "             label=labels[0]\n",
    "            )\n",
    "\n",
    "    hist, bins = np.histogram(metrics2, bins=bins, density=True);\n",
    "    plt.plot(x[hist>0],hist[hist>0],'o-',\n",
    "                 markersize='12',\n",
    "                 color=sns.color_palette(cmName1)[0],\n",
    "                 label=labels[1]\n",
    "                )\n",
    "    \n",
    "    ax.lines[0].set(linewidth=4, linestyle='--', alpha=0.9)\n",
    "    ax.lines[1].set(linewidth=4, linestyle='-', alpha=0.9)\n",
    "\n",
    "    plt.title('Comparison of Degree Distributions',fontproperties=font);\n",
    " \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Degree',fontproperties=font);\n",
    "    ax.set_ylabel('Probability',fontproperties=font);\n",
    "\n",
    "    \n",
    "    plt.legend(fontsize=32,\n",
    "               handletextpad=0.5,\n",
    "               numpoints=2,\n",
    "               frameon=False)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='major',direction='in',length=18 ,labelsize=32,pad=9)\n",
    "    plt.tick_params(axis='x', which='minor',direction='in',length=9)\n",
    "    plt.tick_params(axis='y', which='major',direction='in',length=18 ,labelsize=32)\n",
    "    plt.tick_params(axis='y', which='minor',direction='in',length=9)\n",
    "    \n",
    "    ax.spines['left'].set_linewidth(3)   \n",
    "    ax.spines['bottom'].set_linewidth(3) \n",
    "    ax.spines['right'].set_linewidth(3)  \n",
    "    ax.spines['top'].set_linewidth(3)    \n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f344a-6298-4182-8f0f-c3cb1a61385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.95\n",
    "G1 = create_network(corr1, nucIndex, th)\n",
    "G2 = create_network(corr2, nucNo, th)\n",
    "metrics1 = calculate_metrics(G1)\n",
    "metrics2 = calculate_metrics(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95426646-3aaa-42fd-a36b-9f42b372e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_hist('degree', metrics1,metrics2,G1,G2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
